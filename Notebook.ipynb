{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Neural Networks in PyTorch\n",
    "### Companion Notebook for the Medium Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader  # For custom dataset and batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection, Preprocessing, and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ./data/train-images-idx3-ubyte.gz...\n",
      "Downloaded ./data/train-images-idx3-ubyte.gz\n",
      "Downloading ./data/train-labels-idx1-ubyte.gz...\n",
      "Downloaded ./data/train-labels-idx1-ubyte.gz\n",
      "Downloading ./data/t10k-images-idx3-ubyte.gz...\n",
      "Downloaded ./data/t10k-images-idx3-ubyte.gz\n",
      "Downloading ./data/t10k-labels-idx1-ubyte.gz...\n",
      "Downloaded ./data/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data/t10k-images-idx3-ubyte.gz...\n",
      "Extracted to ./data/t10k-images-idx3-ubyte\n",
      "Extracting ./data/train-images-idx3-ubyte.gz...\n",
      "Extracted to ./data/train-images-idx3-ubyte\n",
      "Extracting ./data/train-labels-idx1-ubyte.gz...\n",
      "Extracted to ./data/train-labels-idx1-ubyte\n",
      "Extracting ./data/t10k-labels-idx1-ubyte.gz...\n",
      "Extracted to ./data/t10k-labels-idx1-ubyte\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "# Updated URLs for MNIST dataset\n",
    "urls = [\n",
    "    \"https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\",\n",
    "    \"https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\",\n",
    "    \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\",\n",
    "    \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\"\n",
    "]\n",
    "\n",
    "# Directory to store data\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "# Function to download files\n",
    "def download_file(url, save_dir=\"./data\"):\n",
    "    filename = os.path.join(save_dir, url.split(\"/\")[-1])\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        with open(filename, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                f.write(chunk)\n",
    "        print(f\"Downloaded {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {url}: {response.status_code}\")\n",
    "\n",
    "# Download all files\n",
    "for url in urls:\n",
    "    download_file(url)\n",
    "\n",
    "# Function to extract .gz files\n",
    "def extract_gz_files(source_dir=\"./data\"):\n",
    "    for file in os.listdir(source_dir):\n",
    "        if file.endswith(\".gz\"):\n",
    "            file_path = os.path.join(source_dir, file)\n",
    "            extracted_path = file_path.replace(\".gz\", \"\")\n",
    "            print(f\"Extracting {file_path}...\")\n",
    "            with gzip.open(file_path, 'rb') as f_in:\n",
    "                with open(extracted_path, 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "            print(f\"Extracted to {extracted_path}\")\n",
    "\n",
    "# Extract all downloaded files\n",
    "extract_gz_files(\"./data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images Shape: (60000, 28, 28)\n",
      "Train Labels Shape: (60000,)\n",
      "Test Images Shape: (10000, 28, 28)\n",
      "Test Labels Shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "def load_images(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        # Read the header\n",
    "        magic, num_images, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        assert magic == 2051, \"Invalid magic number for image file!\"\n",
    "        # Read the image data and reshape it\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num_images, rows, cols)\n",
    "    return images\n",
    "\n",
    "def load_labels(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        # Read the header\n",
    "        magic, num_labels = struct.unpack(\">II\", f.read(8))\n",
    "        assert magic == 2049, \"Invalid magic number for label file!\"\n",
    "        # Read the label data\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "# Load training data\n",
    "train_images = load_images('./data/train-images-idx3-ubyte')\n",
    "train_labels = load_labels('./data/train-labels-idx1-ubyte')\n",
    "\n",
    "# Load test data\n",
    "test_images = load_images('./data/t10k-images-idx3-ubyte')\n",
    "test_labels = load_labels('./data/t10k-labels-idx1-ubyte')\n",
    "\n",
    "# Print shapes for verification\n",
    "print(f\"Train Images Shape: {train_images.shape}\")\n",
    "print(f\"Train Labels Shape: {train_labels.shape}\")\n",
    "print(f\"Test Images Shape: {test_images.shape}\")\n",
    "print(f\"Test Labels Shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select an image and label to display\n",
    "index = 1  # Change this to see other images\n",
    "image = train_images[index].astype(np.float32)  # Convert to float for better rendering\n",
    "label = train_labels[index]\n",
    "\n",
    "# Plot the image\n",
    "def show_image(image,label):\n",
    "    plt.imshow(image, cmap='gray', interpolation='nearest')  # Ensure grayscale rendering\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.axis('off')  # Remove axis for clarity\n",
    "    plt.show()\n",
    "\n",
    "show_image(image,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Custom PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Custom MNIST dataset.\n",
    "        Args:\n",
    "            images: NumPy array or tensor of shape (N, 28, 28).\n",
    "            labels: NumPy array or tensor of shape (N,).\n",
    "            transform: Optional. A callable that applies transformations to the images.\n",
    "        \"\"\"\n",
    "        # Convert NumPy arrays to tensors during initialization\n",
    "        self.images = torch.tensor(images, dtype=torch.float32) #Default is usually float32\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long) # Type long for classification\n",
    "        self.transform = transform if transform else self.default_transform() #Apply default transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Fetch an image and its corresponding label.\n",
    "        Args:\n",
    "            idx: Index of the image and label to retrieve.\n",
    "        Returns:\n",
    "            Tuple (transformed_image, label).\n",
    "        \"\"\"\n",
    "        # Access the image and label directly as tensors\n",
    "        image = self.images[idx].unsqueeze(0)  # Add channel dimension (C, H, W)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Apply the transform\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def default_transform(self):\n",
    "        \"\"\"\n",
    "        Define the default transformation pipeline for MNIST.\n",
    "        Returns:\n",
    "            A callable transform.\n",
    "        \"\"\"\n",
    "        return transforms.Compose([\n",
    "            transforms.Normalize((0.5,), (0.5,)),  # Normalize to mean 0.5, std 0.5\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNISTDataset(train_images, train_labels).images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Normalize(mean=(0.5,), std=(0.5,))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNISTDataset(train_images, train_labels).default_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNISTDataset(train_images, train_labels).__getitem__(1)[0].shape# Return \"image\" at idx 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNISTDataset(train_images, train_labels).__getitem__(1)[1] # Return label at idx 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(MNISTDataset(train_images, train_labels), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(MNISTDataset(test_images, test_labels), batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining A Simple Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleFCNN(nn.Module):\n",
    "    def __init__(self, input_size=28*28, hidden_size=128, output_size=10):\n",
    "        \"\"\"\n",
    "        Fully connected neural network with a single hidden layer.\n",
    "        Args:\n",
    "            input_size (int): Number of input features (e.g., 28*28 for MNIST).\n",
    "            hidden_size (int): Size of the hidden layer.\n",
    "            output_size (int): Number of output classes (e.g., 10 for MNIST digits).\n",
    "        \"\"\"\n",
    "        super(SimpleFCNN, self).__init__()\n",
    "        \n",
    "        # Define the network layers\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),  # Input to hidden layer\n",
    "            nn.ReLU(),                           # Activation function\n",
    "            nn.Linear(hidden_size, output_size)  # Hidden to output layer\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor (batch_size, input_size).\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor (batch_size, output_size).\n",
    "        \"\"\"\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleFCNN(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimpleFCNN(input_size=28*28, hidden_size=128, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "basic_model = SimpleFCNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
    "optimizer = optim.Adam(basic_model.parameters(), lr=0.001)  # Learning rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network.0.weight: torch.Size([128, 784])\n",
      "network.0.bias: torch.Size([128])\n",
      "network.2.weight: torch.Size([10, 128])\n",
      "network.2.bias: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Shows all trainable parameters\n",
    "for name, param in basic_model.state_dict().items():\n",
    "    print(f\"{name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluate a PyTorch model on a test dataset.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to evaluate\n",
    "        test_loader (DataLoader): DataLoader containing the test dataset\n",
    "        \n",
    "    Returns:\n",
    "        float: Accuracy percentage on the test dataset\n",
    "    \"\"\"\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Disable gradient computation for evaluation\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Get predicted class (highest score)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Update total and correct counts\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate and return accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy  # Return the value instead of printing it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.7"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(basic_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, verbose=True):\n",
    "    \"\"\"\n",
    "    Train a PyTorch model for one epoch.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): PyTorch model to train\n",
    "        train_loader (DataLoader): DataLoader for training data\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer for updating weights\n",
    "        verbose (bool): Whether to print progress\n",
    "        \n",
    "    Returns:\n",
    "        float: Average loss for the epoch\n",
    "    \"\"\"\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    total_loss = 0\n",
    "    total_batches = len(train_loader)\n",
    "    \n",
    "    # Training loop\n",
    "    for _, (images, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Calculate average loss\n",
    "    avg_loss = total_loss / total_batches\n",
    "    \n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9196185972025273"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(basic_model, train_loader, criterion, optimizer, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model After 1 Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.09"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(basic_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Additional Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=5):\n",
    "    \"\"\"\n",
    "    Train a model for multiple epochs and evaluate performance.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to train\n",
    "        train_loader: DataLoader for training data\n",
    "        test_loader: DataLoader for test data\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer for updating weights\n",
    "        num_epochs: Number of epochs to train\n",
    "    \n",
    "    Returns:\n",
    "        dict: Training history with losses and accuracies\n",
    "    \"\"\"\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'test_accuracy': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n=== Epoch {epoch + 1}/{num_epochs} ===\")\n",
    "        \n",
    "        # Train for one epoch\n",
    "        avg_loss = train_epoch(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer\n",
    "        )\n",
    "        history['train_loss'].append(avg_loss)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_acc = evaluate_model(model, test_loader)\n",
    "        history['test_accuracy'].append(test_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {avg_loss:.4f}\")\n",
    "        print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 1/9 ===\n",
      "Train Loss: 0.2248\n",
      "Test Accuracy: 94.21%\n",
      "\n",
      "=== Epoch 2/9 ===\n",
      "Train Loss: 0.1938\n",
      "Test Accuracy: 95.02%\n",
      "\n",
      "=== Epoch 3/9 ===\n",
      "Train Loss: 0.1909\n",
      "Test Accuracy: 94.42%\n",
      "\n",
      "=== Epoch 4/9 ===\n",
      "Train Loss: 0.1899\n",
      "Test Accuracy: 93.31%\n",
      "\n",
      "=== Epoch 5/9 ===\n",
      "Train Loss: 0.1909\n",
      "Test Accuracy: 95.02%\n",
      "\n",
      "=== Epoch 6/9 ===\n",
      "Train Loss: 0.1784\n",
      "Test Accuracy: 94.62%\n",
      "\n",
      "=== Epoch 7/9 ===\n",
      "Train Loss: 0.1782\n",
      "Test Accuracy: 94.53%\n",
      "\n",
      "=== Epoch 8/9 ===\n",
      "Train Loss: 0.1713\n",
      "Test Accuracy: 94.52%\n",
      "\n",
      "=== Epoch 9/9 ===\n",
      "Train Loss: 0.1747\n",
      "Test Accuracy: 94.53%\n"
     ]
    }
   ],
   "source": [
    "history = train_model(\n",
    "    model=basic_model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleImprovedFCNN(nn.Module):\n",
    "    def __init__(self, input_size=28*28, hidden_size=128, output_size=10):\n",
    "        super(SimpleImprovedFCNN, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size), \n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),  # Add dropout layer\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.network(x)\n",
    "\n",
    "# Initialize new model and optimizer\n",
    "improved_model = SimpleImprovedFCNN()\n",
    "optimizer = optim.Adam(improved_model.parameters(), lr=0.001)  # Create new optimizer\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Augmentation to Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_augmented_transforms():\n",
    "    \"\"\"\n",
    "    Create augmented transformation pipeline for MNIST dataset.\n",
    "    Returns:\n",
    "        transforms.Compose: Composition of transforms with augmentation\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomAffine(\n",
    "            degrees=10,  # Random rotation up to 10 degrees\n",
    "            translate=(0.1, 0.1),  # Random translation up to 10%\n",
    "            scale=(0.9, 1.1),  # Random scaling between 90% and 110%\n",
    "        ),\n",
    "        transforms.RandomApply([\n",
    "            transforms.GaussianBlur(kernel_size=3)  # Random Gaussian blur\n",
    "        ], p=0.2),\n",
    "        transforms.Normalize((0.5,), (0.5,)),  # Normalize to mean 0.5, std 0.5\n",
    "    ])\n",
    "\n",
    "# Usage example:\n",
    "train_dataset_aug = MNISTDataset(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    transform=get_mnist_augmented_transforms()  # Pass in augmented transforms\n",
    ")\n",
    "\n",
    "# For test data, use default transforms\n",
    "test_dataset_aug = MNISTDataset(\n",
    "    test_images, \n",
    "    test_labels  # Uses default_transform() internally\n",
    ")\n",
    "\n",
    "train_loader_aug = DataLoader(train_dataset_aug, batch_size=64, shuffle=True)\n",
    "test_loader_aug = DataLoader(test_dataset_aug, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDropoutFCNN(nn.Module):\n",
    "    def __init__(self, input_size=28*28, hidden_size=128, output_size=10):\n",
    "        super(SimpleDropoutFCNN, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # Add dropout layer\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.network(x)\n",
    "\n",
    "# Initialize new model and optimizer\n",
    "dropout_model = SimpleDropoutFCNN()\n",
    "optimizer = optim.Adam(dropout_model.parameters(), lr=0.001)  # Create new optimizer\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNISTDataset(train_images, train_labels).images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNISTDataset(train_images, train_labels).labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Class: 5, Predicted Class: 5, Confidence: 94.6%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "image = MNISTDataset(train_images, train_labels).images[0]\n",
    "image_label = MNISTDataset(train_images, train_labels).labels[0]\n",
    "image = image.view(1, -1)\n",
    "\n",
    "# Forward pass\n",
    "logits = dropout_model(image)  # Get raw logits from the model\n",
    "\n",
    "# Apply softmax to get probabilities\n",
    "probabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "# Extract predicted class and its confidence\n",
    "confidence, predicted_class = torch.max(probabilities, dim=1)\n",
    "\n",
    "# Print results\n",
    "print(f\"Actual Class: {image_label}, Predicted Class: {predicted_class.item()}, Confidence: {confidence.item()*100:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
